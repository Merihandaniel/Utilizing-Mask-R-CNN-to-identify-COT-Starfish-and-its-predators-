# -*- coding: utf-8 -*-
"""COTS Data_Exploration and Data Processing

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kUmbWCT5agScZa5XwnHoHwJHBR0iBca5
"""

!git clone https://github.com/JessicaWoods03/data_analysis_work.git
!git clone https://github.com/ahmedfgad/Mask-RCNN-TF2

#importing packages
import tensorflow as tf
import cv2
import os
import matplotlib.pyplot as plt
import pandas as pd
import json

!pwd

# Commented out IPython magic to ensure Python compatibility.
# %cd data_analysis_work/
!ls

directories = ['first_50', 'second_50', 'third_50', 'fourth_50', 'fifth_50', 'sixth_50']
directoryCSV = ['annotations_1']

all_photos = []

def load_photos_from_directory(directory):
    photos = []
    for filename in os.listdir(directory):
        if filename.endswith(".jpg"):
            photo_path = os.path.join(directory, filename)
            photo = cv2.imread(photo_path)
            if photo is not None:
                photos.append(photo)
    return photos

for directory in directories:
    try:
#         %cd "{directory}"
        !ls
        photos = load_photos_from_directory('.')
        all_photos.extend(photos)
#         %cd ..
    except FileNotFoundError:
        print(f"Directory '{directory}' not found.")

"""Github has a limit of like 51 images per load before the file is too big..
I need to ensure that we have a static link to the file so we both can work on this together in colabs-
"""

# Commented out IPython magic to ensure Python compatibility.
directory = 'labeled_images'

all_json_data = []

def load_json_from_directory(directory):
    json_data = []
    for filename in os.listdir(directory):
        if filename.endswith(".json"):
            with open(os.path.join(directory, filename), 'r') as json_file:
                data = json.load(json_file)
                json_data.append(data)
    return json_data

try:
#     %cd "{directory}"
    !ls
    json_data = load_json_from_directory('.')
    all_json_data.extend(json_data)
#     %cd ..

except FileNotFoundError:
    print(f"Directory '{directory}' not found.")

df_csv = ''
try:
#     %cd "{directoryCSV}"
    df_csv = pd.read_csv('annotations_1.csv')
    print(df_csv)
#     %cd ..
except FileNotFoundError:
    print(f"Directory '{directoryCSV}' not found.")

"""xmin: The x-coordinate of the top-left corner of the bounding box.<br>
ymin: The y-coordinate of the top-left corner of the bounding box.<br>
xmax: The x-coordinate of the bottom-right corner of the bounding box.<br>
ymax: The y-coordinate of the bottom-right corner of the bounding box.<br>

"""

df_csv.head()

df_csv.shape

# bounding box statistics
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

df_csv['width'] = df_csv['xmax'] - df_csv['xmin']
df_csv['height'] = df_csv['ymax'] - df_csv['ymin']
df_csv['aspect_ratio'] = df_csv['width'] / df_csv['height']

# histograms of width and height
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.hist(df_csv['width'], bins=50, color='blue', alpha=0.7)
plt.xlabel('Width')
plt.ylabel('Frequency')
plt.title('Histogram of Object Widths')

plt.subplot(1, 2, 2)
plt.hist(df_csv['height'], bins=50, color='green', alpha=0.7)
plt.xlabel('Height')
plt.ylabel('Frequency')
plt.title('Histogram of Object Heights')

plt.tight_layout()
plt.show()

# Scatter plot of object aspect ratios
plt.figure(figsize=(8, 6))
plt.scatter(df_csv['width'], df_csv['height'], color='red', alpha=0.5)
plt.xlabel('Width')
plt.ylabel('Height')
plt.title('Scatter Plot of Object Sizes (Width vs. Height)')
plt.grid(True)
plt.show()

# histogram of object aspect ratios
plt.figure(figsize=(8, 6))
plt.hist(df_csv['aspect_ratio'], bins=50, color='orange', alpha=0.7)
plt.xlabel('Aspect Ratio')
plt.ylabel('Frequency')
plt.title('Histogram of Object Aspect Ratios')
plt.show()

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/data_analysis_work/

!ls

# Commented out IPython magic to ensure Python compatibility.
# Loading JSON files from labeled images 1 and 2
json_100_data = []

try:

#     %cd "labeled_images"
    !ls

    json_data = load_json_from_directory('.')
    json_100_data.extend(json_data)

#     %cd ..

except FileNotFoundError:
    print(f"Directory '{directory}' not found.")

directory2 = 'labeled_images_2'
try:
#     %cd "{directory2}"
    !ls
    json_data = load_json_from_directory('.')

    json_100_data.extend(json_data)

#     %cd ..

except FileNotFoundError:
    print(f"Directory '{directory}' not found.")
print(f"Number of json loaded: {len(json_100_data)}")

"""**Data Exploration**"""

# Loading all photos using OpenCV
import cv2
import os
from google.colab.patches import cv2_imshow

print(f"Number of photos loaded: {len(all_photos)}")

if len(all_photos) > 0:
    cv2_imshow(all_photos[0])
else:
    print("No photos found in the directory.")

# Check if any photos are loaded
if len(all_photos) > 0:
    image = all_photos[0]
    if len(image.shape) == 2 or image.shape[2] == 1:
        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)
    elif image.shape[2] == 4:
        image = cv2.cvtColor(image, cv2.COLOR_RGBA2RGB)
    elif image.shape[2] == 3:
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    plt.imshow(image)
    plt.axis('off')
    plt.show()

for idx, image in enumerate(all_photos):
    print(f"Image {idx}: shape = {image.shape}, dtype = {image.dtype}")

print(all_photos, "Sample Image Grid")

import cv2
import numpy as np
from google.colab.patches import cv2_imshow

def photo_grid(images, grid_size=(2, 5), image_size=(1280, 720)):

    rows, cols = grid_size
    width, height = image_size

    grid_image = np.zeros((height * rows, width * cols, 3), dtype=np.uint8)

    for idx, image in enumerate(images):
        if idx >= rows * cols:
            break
        resized_image = cv2.resize(image, (width, height))
        row = idx // cols
        col = idx % cols

        grid_image[row * height:(row + 1) * height, col * width:(col + 1) * width, :] = resized_image

    return grid_image

combined_image = photo_grid(all_photos, grid_size=(2, 5), image_size=(1280, 720))

cv2_imshow(combined_image)

import cv2
import matplotlib.pyplot as plt

# Function to calculate dimensions and aspect ratios
def calculate_image_stats(images):
    dimensions = []
    aspect_ratios = []

    for idx, image in enumerate(images):
        height, width = image.shape[:2]
        dimensions.append((width, height))
        aspect_ratio = width / height
        aspect_ratios.append(aspect_ratio)
        print(f"Image {idx}: Width = {width}, Height = {height}, Aspect Ratio = {aspect_ratio:.2f}")

    return dimensions, aspect_ratios
dimensions, aspect_ratios = calculate_image_stats(all_photos)

# Aspect ratios
plt.hist(aspect_ratios, bins=20, edgecolor='black')
plt.title('Aspect Ratio Distribution')
plt.xlabel('Aspect Ratio')
plt.ylabel('Frequency')
plt.show()

# dimensions
widths, heights = zip(*dimensions)
plt.scatter(widths, heights, alpha=0.5)
plt.title('Image Dimensions')
plt.xlabel('Width')
plt.ylabel('Height')
plt.show()

import json
import matplotlib.pyplot as plt
from collections import Counter

bounding_box_sizes = []
aspect_ratios = []
labels = []

for annotation in json_100_data:
    if '_via_img_metadata' in annotation:
        img_metadata = annotation['_via_img_metadata']
        for image_id, image_data in img_metadata.items():
            if 'regions' in image_data:
                for region in image_data['regions']:
                    if 'shape_attributes' in region:
                        shape_attributes = region['shape_attributes']
                        width = shape_attributes.get('width')
                        height = shape_attributes.get('height')
                        if width is not None and height is not None:
                            bounding_box_size = width * height
                            aspect_ratio = width / height
                            bounding_box_sizes.append((width, height))
                            aspect_ratios.append(aspect_ratio)
                            print(f"Processed bounding box: Width = {width}, Height = {height}, Size = {bounding_box_size}, Aspect Ratio = {aspect_ratio:.2f}")

                            if 'region_attributes' in region:
                                region_attributes = region['region_attributes']
                                label = region_attributes.get('species', 'Unknown')
                                labels.append(label)

# Analyzing label distribution
label_counts = Counter(labels)
print("Label distribution:", label_counts)

# Plot label distribution
plt.bar(label_counts.keys(), label_counts.values())
plt.title("Label Distribution")
plt.xlabel("Labels")
plt.ylabel("Frequency")
plt.xticks(rotation=90)
plt.show()

# Plot bounding box sizes
widths, heights = zip(*bounding_box_sizes)
plt.hist([w * h for w, h in bounding_box_sizes], bins=20, edgecolor='black')
plt.title('Bounding Box Size Distribution')
plt.xlabel('Bounding Box Size')
plt.ylabel('Frequency')
plt.show()

# Plot aspect ratios
plt.hist(aspect_ratios, bins=20, edgecolor='black')
plt.title('Aspect Ratio Distribution')
plt.xlabel('Aspect Ratio')
plt.ylabel('Frequency')
plt.show()

# Scatter plot of bounding box sizes
plt.scatter(widths, heights, alpha=0.5)
plt.title('Bounding Box Dimensions')
plt.xlabel('Width')
plt.ylabel('Height')
plt.show()

"""**Evaluate using Machine learning Model: Random Forest**"""

nan_values = df_csv.isna().sum()
print("NaN values per column:")
print(nan_values)

nan_values_in_species_column = df_csv['species'].isna().sum()
print("\nNaN values in 'species' column:", nan_values_in_species_column)

df_clean = df_csv.dropna()

nan_values = df_clean.isna().sum()
print("NaN values per column:")
print(nan_values)

df_clean.shape

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

bounding_box_count = df_clean.groupby('filename').size().reset_index(name='bounding_box_count')

df_merged = pd.merge(df_clean, bounding_box_count, on='filename')

X = df_merged[['bounding_box_count']]
y = df_merged['species']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = LogisticRegression()

model.fit(X_train, y_train)

y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# count of bounding boxes per file
df_merged = pd.merge(df_clean, bounding_box_count, on='filename')
species_per_filename_pivot = df_merged.pivot_table(index='filename', columns='species', values='bounding_box_count', aggfunc='sum').fillna(0)

# heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(species_per_filename_pivot, cmap='YlGnBu', linewidths=0.5)
plt.title('Distribution of Species per Filename')
plt.xlabel('Species')
plt.ylabel('Filename')
plt.show()

# species frequency
plt.figure(figsize=(12, 8))
sns.countplot(data=df_csv, x='species', order=df_csv['species'].value_counts().index)
plt.title('Frequency of Species')
plt.xlabel('Species')
plt.ylabel('Frequency')
plt.xticks(rotation=45)
plt.show()

from sklearn.ensemble import RandomForestClassifier
# Random Forest model
model_rf = RandomForestClassifier(n_estimators=100, random_state=42)

model_rf.fit(X_train, y_train)

y_pred_rf = model_rf.predict(X_test)

accuracy_rf = accuracy_score(y_test, y_pred_rf)
print("Random Forest Accuracy:", accuracy_rf)

from sklearn.utils.class_weight import compute_class_weight
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

X = df_merged[['bounding_box_count']]
y = df_merged['species']

class_labels = df_merged['species'].unique()
class_weights = compute_class_weight(class_weight='balanced', classes=class_labels, y=y)

class_weight_dict = dict(zip(class_labels, class_weights))

model_rf_weighted = RandomForestClassifier(n_estimators=100, random_state=42, class_weight=class_weight_dict)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model_rf_weighted.fit(X_train, y_train)

y_pred_rf_weighted = model_rf_weighted.predict(X_test)

accuracy_rf_weighted = accuracy_score(y_test, y_pred_rf_weighted)
print("Random Forest Accuracy with Class Weights:", accuracy_rf_weighted)

from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report

accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
class_report = classification_report(y_test, y_pred)

print(f"Accuracy: {accuracy}")
print("Confusion Matrix:")
print(conf_matrix)
print("Classification Report:")
print(class_report)

# confusion matrix
plt.figure(figsize=(10, 7))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=set(y), yticklabels=set(y))
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

# classification report
report = classification_report(y_test, y_pred, output_dict=True)
report_df = pd.DataFrame(report).transpose()

plt.figure(figsize=(10, 7))
sns.heatmap(report_df.iloc[:-1, :-1].T, annot=True, cmap='Blues')
plt.title('Classification Report')
plt.show()

#Running MASK RCNN model

!ls Mask_RCNN-TF2

# Commented out IPython magic to ensure Python compatibility.
# %cd ..

# Commented out IPython magic to ensure Python compatibility.
# %cd Mask-RCNN-TF2

# Commented out IPython magic to ensure Python compatibility.
# Importing Mask R-CNN repository
#!git clone https://github.com/matterport/Mask_RCNN.git
# %cd Mask_RCNN-TF2
!python setup.py install
!pip install -r requirements.txt

import datetime
def via_to_coco(via_json_data):
    coco_data = {
        "info": {
            "description": "Dataset converted from VIA annotations",
            "url": "",
            "version": "1.0",
            "year": datetime.datetime.now().year,
            "contributor": "",
            "date_created": datetime.datetime.now().isoformat()
        },
        "licenses": [],
        "images": [],
        "annotations": [],
        "categories": []
    }

    category_mapping = {
        "F_coral": 1,
        "S_coral": 2,
        "COT": 3,
        "surgeonfish": 4
    }

    for name, id in category_mapping.items():
        coco_data["categories"].append({
            "id": id,
            "name": name,
            "supercategory": "none"
        })
    annotation_id = 1
    for data_dict in via_json_data:
      if '_via_img_metadata' in data_dict:
        for file_data in data_dict['_via_img_metadata'].values():
            print(file_data)
            file_name = file_data['filename']
            file_regions = file_data['regions']
            image_id = int(os.path.splitext(file_name)[0])

            coco_data["images"].append({
                "id": image_id,
                "width": file_data.get('width', 1280),
                "height": file_data.get('height', 720),
                "file_name": file_name,
                "license": 0,
                "flickr_url": "",
                "coco_url": "",
                "date_captured": datetime.datetime.now().isoformat()
            })

            for region in file_regions:
                shape_attributes = region['shape_attributes']
                region_attributes = region['region_attributes']
                category_name = region_attributes.get('name')
                category_id = category_mapping.get('species')
                bbox = [shape_attributes['x'], shape_attributes['y'],
                        shape_attributes['width'], shape_attributes['height']]
                segmentation = [[
                    shape_attributes['x'], shape_attributes['y'],
                    shape_attributes['x'] + shape_attributes['width'], shape_attributes['y'],
                    shape_attributes['x'] + shape_attributes['width'], shape_attributes['y'] + shape_attributes['height'],
                    shape_attributes['x'], shape_attributes['y'] + shape_attributes['height']
                ]]

                coco_data["annotations"].append({
                    "id": annotation_id,
                    "image_id": image_id,
                    "category_id": category_id,
                    "bbox": bbox,
                    "segmentation": segmentation,
                    "area": shape_attributes['width'] * shape_attributes['height'],
                    "iscrowd": 0
                })
                annotation_id += 1

    return coco_data

coco_data = via_to_coco(json_100_data)

with open('../data_analysis_work/annotations.json', 'w') as outfile:
    json.dump(coco_data, outfile)

from mrcnn.config import Config
from mrcnn import utils

class CustomConfig(Config):
    NAME = "coral"
    IMAGES_PER_GPU = 2
    NUM_CLASSES = 1 + 4
    STEPS_PER_EPOCH = 100
    DETECTION_MIN_CONFIDENCE = 0.9

class CustomDataset(utils.Dataset):
    def load_custom(self, annotation_json, images_dir):

        # annotations loaded
        with open(annotation_json) as f:
            annotations = json.load(f)

        for category in annotations['categories']:
            self.add_class("coral", category['id'], category['name'])

        # images added
        for image in annotations['images']:
            image_path = os.path.join(images_dir, image['file_name'])
            self.add_image(
                "coral",
                image_id=image['id'],
                path=image_path,
                width=image['width'],
                height=image['height'],
                annotations=[a for a in annotations['annotations'] if a['image_id'] == image['id']]
            )

    def load_mask(self, image_id):
        info = self.image_info[image_id]
        annotations = info['annotations']
        masks = np.zeros([info['height'], info['width'], len(annotations)], dtype=np.uint8)
        class_ids = np.zeros(len(annotations), dtype=np.int32)

        for i, annotation in enumerate(annotations):
            bbox = annotation['bbox']
            mask = np.zeros([info['height'], info['width']], dtype=np.uint8)
            mask[bbox[1]:bbox[1]+bbox[3], bbox[0]:bbox[0]+bbox[2]] = 1
            masks[:, :, i] = mask
            class_ids[i] = annotation['category_id']

        return masks, class_ids.astype(np.int32)

# Mask R-CNN imports
from mrcnn.model import MaskRCNN
from mrcnn.config import Config
from mrcnn import model as modellib, utils
from mrcnn.visualize import display_instances
from mrcnn.model import log

# Training dataset
dataset_train = CustomDataset()
print(type(dataset_train))
dataset_train.load_custom('../data_analysis_work/annotations.json', '/content/data_analysis_work/labeled_images')
dataset_train.prepare()

# Validation dataset
dataset_val = CustomDataset()
dataset_val.load_custom('../data_analysis_work/annotations.json', '/content/data_analysis_work/labeled_images_2')
dataset_val.prepare()

# Creating MASK-R-CNN model
config = CustomConfig()
model = modellib.MaskRCNN(mode="training", config=config, model_dir='/content/logs')

#utilizing pre-trained model
COCO_MODEL_PATH = 'mask_rcnn_coco.h5'
model.load_weights(COCO_MODEL_PATH, by_name=True, exclude=[
    "mrcnn_class_logits", "mrcnn_bbox_fc", "mrcnn_bbox", "mrcnn_mask"])

# Model training
model.train(dataset_train, dataset_val,
            learning_rate=config.LEARNING_RATE,
            epochs=30,
            layers='heads')

"""Model doesnt work on google collab or jupyter notebook
- Debugging:
MRCNN model requires older versions of Python and TensorFlow to run, specifically Python 3.6.0 and TensorFlow 2.0.0. Also, Google Colab's environment only supports Python 3.8.0 and above and TensorFlow 2.15.0 and above.

Thus, this model was not able to run due to the outdated python/TF packages that is incompatable with google collab/jupyter notebook/kaggle notebook IDE environment, which was tested on.
"""